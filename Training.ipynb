{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/AI/neurowood/\n",
    "!ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5YcurT6Tmqf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650120151780,
     "user_tz": -120,
     "elapsed": 2165,
     "user": {
      "displayName": "Nikita Dilman",
      "userId": "06419702465665096398"
     }
    },
    "outputId": "d37dbd6f-ae97-417b-846c-65030d74da25"
   },
   "id": "O5YcurT6Tmqf",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/AI/neurowood\n",
      "ConvNeXt  Ensemble.ipynb\t\t\tsubmit.csv\tViT\n",
      "data\t  image_classification_explained.ipynb\tTraining.ipynb\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConvNext"
   ],
   "metadata": {
    "id": "3xaauh7T2kUQ"
   },
   "id": "3xaauh7T2kUQ"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq wandb timm==0.4.12 six tensorboardX"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8ALeVdF4mNW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1649953750205,
     "user_tz": -120,
     "elapsed": 8925,
     "user": {
      "displayName": "Nikita Dilman",
      "userId": "06419702465665096398"
     }
    },
    "outputId": "bf978422-e374-4a14-ff22-67642b8e34b9"
   },
   "id": "J8ALeVdF4mNW",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[K     |████████████████████████████████| 1.8 MB 7.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 376 kB 45.2 MB/s \n",
      "\u001B[K     |████████████████████████████████| 125 kB 55.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 181 kB 52.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 144 kB 54.2 MB/s \n",
      "\u001B[K     |████████████████████████████████| 63 kB 831 kB/s \n",
      "\u001B[?25h  Building wheel for pathtools (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c9b72",
   "metadata": {
    "cellId": "kawv9k4vbci0tj004869n5r",
    "id": "5b5c9b72",
    "outputId": "1c731e9d-9b7d-4409-e0a4-e5c663ee970b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1649953762880,
     "user_tz": -120,
     "elapsed": 12679,
     "user": {
      "displayName": "Nikita Dilman",
      "userId": "06419702465665096398"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mkdir: cannot create directory ‘ConvNeXt/weights’: File exists\n",
      "--2022-04-14 16:29:12--  https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_384.pth\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 354476359 (338M) [binary/octet-stream]\n",
      "Saving to: ‘ConvNeXt/weights/convnext_base_1k_384.pth.1’\n",
      "\n",
      "convnext_base_1k_38 100%[===================>] 338.05M  22.6MB/s    in 12s     \n",
      "\n",
      "2022-04-14 16:29:24 (29.1 MB/s) - ‘ConvNeXt/weights/convnext_base_1k_384.pth.1’ saved [354476359/354476359]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir ConvNeXt/weights\n",
    "!wget https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_384.pth -P ConvNeXt/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188e890",
   "metadata": {
    "cellId": "vczvg5pniczwzkti15h6g",
    "id": "0188e890",
    "outputId": "5631c1a4-d916-45f8-e653-1a0f22c18bb5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1649954798585,
     "user_tz": -120,
     "elapsed": 363220,
     "user": {
      "displayName": "Nikita Dilman",
      "userId": "06419702465665096398"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: 'ConvNeXt'\n",
      "/content/drive/MyDrive/AI/neurowood/ConvNeXt\n",
      "Not using distributed mode\n",
      "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=4, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=0.0, cutmix_minmax=None, data_path='../data/', data_set='image_folder', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0, enable_wandb=False, epochs=15, eval=False, eval_data_path=None, finetune='weights/convnext_base_1k_384.pth', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=384, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.0004, min_lr=1e-06, mixup=0.0, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_base', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, n_fold=1, nb_classes=3, num_workers=8, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='checkpoints1', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=10, save_ckpt_num=1, seed=0, smoothing=0.0, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=False, warmup_epochs=0, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n",
      "Warping 384 size input images...\n",
      "Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f85ebc1e510>\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "AAAAAAAAAAAAAAAAAAAAAA> convnext_base\n",
      "Load ckpt from weights/convnext_base_1k_384.pth\n",
      "Load state_dict by model_key = model\n",
      "Removing key head.weight from pretrained checkpoint\n",
      "Removing key head.bias from pretrained checkpoint\n",
      "Weights of ConvNeXt not initialized from pretrained model: ['head.weight', 'head.bias']\n",
      "Model = ConvNeXt(\n",
      "  (downsample_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): LayerNorm()\n",
      "      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (12): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (13): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (14): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (15): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (16): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (17): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (18): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (19): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (20): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (21): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (22): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (23): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (24): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (25): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (26): Block(\n",
      "        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Block(\n",
      "        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU()\n",
      "        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Linear(in_features=1024, out_features=3, bias=True)\n",
      ")\n",
      "number of params: 87569539\n",
      "LR = 0.00040000\n",
      "Batch size = 4\n",
      "Update frequent = 1\n",
      "Number of training examples = 385\n",
      "Number of training training per epoch = 96\n",
      "Param groups = {\n",
      "  \"decay\": {\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.weight\",\n",
      "      \"downsample_layers.1.1.weight\",\n",
      "      \"downsample_layers.2.1.weight\",\n",
      "      \"downsample_layers.3.1.weight\",\n",
      "      \"stages.0.0.dwconv.weight\",\n",
      "      \"stages.0.0.pwconv1.weight\",\n",
      "      \"stages.0.0.pwconv2.weight\",\n",
      "      \"stages.0.1.dwconv.weight\",\n",
      "      \"stages.0.1.pwconv1.weight\",\n",
      "      \"stages.0.1.pwconv2.weight\",\n",
      "      \"stages.0.2.dwconv.weight\",\n",
      "      \"stages.0.2.pwconv1.weight\",\n",
      "      \"stages.0.2.pwconv2.weight\",\n",
      "      \"stages.1.0.dwconv.weight\",\n",
      "      \"stages.1.0.pwconv1.weight\",\n",
      "      \"stages.1.0.pwconv2.weight\",\n",
      "      \"stages.1.1.dwconv.weight\",\n",
      "      \"stages.1.1.pwconv1.weight\",\n",
      "      \"stages.1.1.pwconv2.weight\",\n",
      "      \"stages.1.2.dwconv.weight\",\n",
      "      \"stages.1.2.pwconv1.weight\",\n",
      "      \"stages.1.2.pwconv2.weight\",\n",
      "      \"stages.2.0.dwconv.weight\",\n",
      "      \"stages.2.0.pwconv1.weight\",\n",
      "      \"stages.2.0.pwconv2.weight\",\n",
      "      \"stages.2.1.dwconv.weight\",\n",
      "      \"stages.2.1.pwconv1.weight\",\n",
      "      \"stages.2.1.pwconv2.weight\",\n",
      "      \"stages.2.2.dwconv.weight\",\n",
      "      \"stages.2.2.pwconv1.weight\",\n",
      "      \"stages.2.2.pwconv2.weight\",\n",
      "      \"stages.2.3.dwconv.weight\",\n",
      "      \"stages.2.3.pwconv1.weight\",\n",
      "      \"stages.2.3.pwconv2.weight\",\n",
      "      \"stages.2.4.dwconv.weight\",\n",
      "      \"stages.2.4.pwconv1.weight\",\n",
      "      \"stages.2.4.pwconv2.weight\",\n",
      "      \"stages.2.5.dwconv.weight\",\n",
      "      \"stages.2.5.pwconv1.weight\",\n",
      "      \"stages.2.5.pwconv2.weight\",\n",
      "      \"stages.2.6.dwconv.weight\",\n",
      "      \"stages.2.6.pwconv1.weight\",\n",
      "      \"stages.2.6.pwconv2.weight\",\n",
      "      \"stages.2.7.dwconv.weight\",\n",
      "      \"stages.2.7.pwconv1.weight\",\n",
      "      \"stages.2.7.pwconv2.weight\",\n",
      "      \"stages.2.8.dwconv.weight\",\n",
      "      \"stages.2.8.pwconv1.weight\",\n",
      "      \"stages.2.8.pwconv2.weight\",\n",
      "      \"stages.2.9.dwconv.weight\",\n",
      "      \"stages.2.9.pwconv1.weight\",\n",
      "      \"stages.2.9.pwconv2.weight\",\n",
      "      \"stages.2.10.dwconv.weight\",\n",
      "      \"stages.2.10.pwconv1.weight\",\n",
      "      \"stages.2.10.pwconv2.weight\",\n",
      "      \"stages.2.11.dwconv.weight\",\n",
      "      \"stages.2.11.pwconv1.weight\",\n",
      "      \"stages.2.11.pwconv2.weight\",\n",
      "      \"stages.2.12.dwconv.weight\",\n",
      "      \"stages.2.12.pwconv1.weight\",\n",
      "      \"stages.2.12.pwconv2.weight\",\n",
      "      \"stages.2.13.dwconv.weight\",\n",
      "      \"stages.2.13.pwconv1.weight\",\n",
      "      \"stages.2.13.pwconv2.weight\",\n",
      "      \"stages.2.14.dwconv.weight\",\n",
      "      \"stages.2.14.pwconv1.weight\",\n",
      "      \"stages.2.14.pwconv2.weight\",\n",
      "      \"stages.2.15.dwconv.weight\",\n",
      "      \"stages.2.15.pwconv1.weight\",\n",
      "      \"stages.2.15.pwconv2.weight\",\n",
      "      \"stages.2.16.dwconv.weight\",\n",
      "      \"stages.2.16.pwconv1.weight\",\n",
      "      \"stages.2.16.pwconv2.weight\",\n",
      "      \"stages.2.17.dwconv.weight\",\n",
      "      \"stages.2.17.pwconv1.weight\",\n",
      "      \"stages.2.17.pwconv2.weight\",\n",
      "      \"stages.2.18.dwconv.weight\",\n",
      "      \"stages.2.18.pwconv1.weight\",\n",
      "      \"stages.2.18.pwconv2.weight\",\n",
      "      \"stages.2.19.dwconv.weight\",\n",
      "      \"stages.2.19.pwconv1.weight\",\n",
      "      \"stages.2.19.pwconv2.weight\",\n",
      "      \"stages.2.20.dwconv.weight\",\n",
      "      \"stages.2.20.pwconv1.weight\",\n",
      "      \"stages.2.20.pwconv2.weight\",\n",
      "      \"stages.2.21.dwconv.weight\",\n",
      "      \"stages.2.21.pwconv1.weight\",\n",
      "      \"stages.2.21.pwconv2.weight\",\n",
      "      \"stages.2.22.dwconv.weight\",\n",
      "      \"stages.2.22.pwconv1.weight\",\n",
      "      \"stages.2.22.pwconv2.weight\",\n",
      "      \"stages.2.23.dwconv.weight\",\n",
      "      \"stages.2.23.pwconv1.weight\",\n",
      "      \"stages.2.23.pwconv2.weight\",\n",
      "      \"stages.2.24.dwconv.weight\",\n",
      "      \"stages.2.24.pwconv1.weight\",\n",
      "      \"stages.2.24.pwconv2.weight\",\n",
      "      \"stages.2.25.dwconv.weight\",\n",
      "      \"stages.2.25.pwconv1.weight\",\n",
      "      \"stages.2.25.pwconv2.weight\",\n",
      "      \"stages.2.26.dwconv.weight\",\n",
      "      \"stages.2.26.pwconv1.weight\",\n",
      "      \"stages.2.26.pwconv2.weight\",\n",
      "      \"stages.3.0.dwconv.weight\",\n",
      "      \"stages.3.0.pwconv1.weight\",\n",
      "      \"stages.3.0.pwconv2.weight\",\n",
      "      \"stages.3.1.dwconv.weight\",\n",
      "      \"stages.3.1.pwconv1.weight\",\n",
      "      \"stages.3.1.pwconv2.weight\",\n",
      "      \"stages.3.2.dwconv.weight\",\n",
      "      \"stages.3.2.pwconv1.weight\",\n",
      "      \"stages.3.2.pwconv2.weight\",\n",
      "      \"head.weight\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  },\n",
      "  \"no_decay\": {\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"downsample_layers.0.0.bias\",\n",
      "      \"downsample_layers.0.1.weight\",\n",
      "      \"downsample_layers.0.1.bias\",\n",
      "      \"downsample_layers.1.0.weight\",\n",
      "      \"downsample_layers.1.0.bias\",\n",
      "      \"downsample_layers.1.1.bias\",\n",
      "      \"downsample_layers.2.0.weight\",\n",
      "      \"downsample_layers.2.0.bias\",\n",
      "      \"downsample_layers.2.1.bias\",\n",
      "      \"downsample_layers.3.0.weight\",\n",
      "      \"downsample_layers.3.0.bias\",\n",
      "      \"downsample_layers.3.1.bias\",\n",
      "      \"stages.0.0.gamma\",\n",
      "      \"stages.0.0.dwconv.bias\",\n",
      "      \"stages.0.0.norm.weight\",\n",
      "      \"stages.0.0.norm.bias\",\n",
      "      \"stages.0.0.pwconv1.bias\",\n",
      "      \"stages.0.0.pwconv2.bias\",\n",
      "      \"stages.0.1.gamma\",\n",
      "      \"stages.0.1.dwconv.bias\",\n",
      "      \"stages.0.1.norm.weight\",\n",
      "      \"stages.0.1.norm.bias\",\n",
      "      \"stages.0.1.pwconv1.bias\",\n",
      "      \"stages.0.1.pwconv2.bias\",\n",
      "      \"stages.0.2.gamma\",\n",
      "      \"stages.0.2.dwconv.bias\",\n",
      "      \"stages.0.2.norm.weight\",\n",
      "      \"stages.0.2.norm.bias\",\n",
      "      \"stages.0.2.pwconv1.bias\",\n",
      "      \"stages.0.2.pwconv2.bias\",\n",
      "      \"stages.1.0.gamma\",\n",
      "      \"stages.1.0.dwconv.bias\",\n",
      "      \"stages.1.0.norm.weight\",\n",
      "      \"stages.1.0.norm.bias\",\n",
      "      \"stages.1.0.pwconv1.bias\",\n",
      "      \"stages.1.0.pwconv2.bias\",\n",
      "      \"stages.1.1.gamma\",\n",
      "      \"stages.1.1.dwconv.bias\",\n",
      "      \"stages.1.1.norm.weight\",\n",
      "      \"stages.1.1.norm.bias\",\n",
      "      \"stages.1.1.pwconv1.bias\",\n",
      "      \"stages.1.1.pwconv2.bias\",\n",
      "      \"stages.1.2.gamma\",\n",
      "      \"stages.1.2.dwconv.bias\",\n",
      "      \"stages.1.2.norm.weight\",\n",
      "      \"stages.1.2.norm.bias\",\n",
      "      \"stages.1.2.pwconv1.bias\",\n",
      "      \"stages.1.2.pwconv2.bias\",\n",
      "      \"stages.2.0.gamma\",\n",
      "      \"stages.2.0.dwconv.bias\",\n",
      "      \"stages.2.0.norm.weight\",\n",
      "      \"stages.2.0.norm.bias\",\n",
      "      \"stages.2.0.pwconv1.bias\",\n",
      "      \"stages.2.0.pwconv2.bias\",\n",
      "      \"stages.2.1.gamma\",\n",
      "      \"stages.2.1.dwconv.bias\",\n",
      "      \"stages.2.1.norm.weight\",\n",
      "      \"stages.2.1.norm.bias\",\n",
      "      \"stages.2.1.pwconv1.bias\",\n",
      "      \"stages.2.1.pwconv2.bias\",\n",
      "      \"stages.2.2.gamma\",\n",
      "      \"stages.2.2.dwconv.bias\",\n",
      "      \"stages.2.2.norm.weight\",\n",
      "      \"stages.2.2.norm.bias\",\n",
      "      \"stages.2.2.pwconv1.bias\",\n",
      "      \"stages.2.2.pwconv2.bias\",\n",
      "      \"stages.2.3.gamma\",\n",
      "      \"stages.2.3.dwconv.bias\",\n",
      "      \"stages.2.3.norm.weight\",\n",
      "      \"stages.2.3.norm.bias\",\n",
      "      \"stages.2.3.pwconv1.bias\",\n",
      "      \"stages.2.3.pwconv2.bias\",\n",
      "      \"stages.2.4.gamma\",\n",
      "      \"stages.2.4.dwconv.bias\",\n",
      "      \"stages.2.4.norm.weight\",\n",
      "      \"stages.2.4.norm.bias\",\n",
      "      \"stages.2.4.pwconv1.bias\",\n",
      "      \"stages.2.4.pwconv2.bias\",\n",
      "      \"stages.2.5.gamma\",\n",
      "      \"stages.2.5.dwconv.bias\",\n",
      "      \"stages.2.5.norm.weight\",\n",
      "      \"stages.2.5.norm.bias\",\n",
      "      \"stages.2.5.pwconv1.bias\",\n",
      "      \"stages.2.5.pwconv2.bias\",\n",
      "      \"stages.2.6.gamma\",\n",
      "      \"stages.2.6.dwconv.bias\",\n",
      "      \"stages.2.6.norm.weight\",\n",
      "      \"stages.2.6.norm.bias\",\n",
      "      \"stages.2.6.pwconv1.bias\",\n",
      "      \"stages.2.6.pwconv2.bias\",\n",
      "      \"stages.2.7.gamma\",\n",
      "      \"stages.2.7.dwconv.bias\",\n",
      "      \"stages.2.7.norm.weight\",\n",
      "      \"stages.2.7.norm.bias\",\n",
      "      \"stages.2.7.pwconv1.bias\",\n",
      "      \"stages.2.7.pwconv2.bias\",\n",
      "      \"stages.2.8.gamma\",\n",
      "      \"stages.2.8.dwconv.bias\",\n",
      "      \"stages.2.8.norm.weight\",\n",
      "      \"stages.2.8.norm.bias\",\n",
      "      \"stages.2.8.pwconv1.bias\",\n",
      "      \"stages.2.8.pwconv2.bias\",\n",
      "      \"stages.2.9.gamma\",\n",
      "      \"stages.2.9.dwconv.bias\",\n",
      "      \"stages.2.9.norm.weight\",\n",
      "      \"stages.2.9.norm.bias\",\n",
      "      \"stages.2.9.pwconv1.bias\",\n",
      "      \"stages.2.9.pwconv2.bias\",\n",
      "      \"stages.2.10.gamma\",\n",
      "      \"stages.2.10.dwconv.bias\",\n",
      "      \"stages.2.10.norm.weight\",\n",
      "      \"stages.2.10.norm.bias\",\n",
      "      \"stages.2.10.pwconv1.bias\",\n",
      "      \"stages.2.10.pwconv2.bias\",\n",
      "      \"stages.2.11.gamma\",\n",
      "      \"stages.2.11.dwconv.bias\",\n",
      "      \"stages.2.11.norm.weight\",\n",
      "      \"stages.2.11.norm.bias\",\n",
      "      \"stages.2.11.pwconv1.bias\",\n",
      "      \"stages.2.11.pwconv2.bias\",\n",
      "      \"stages.2.12.gamma\",\n",
      "      \"stages.2.12.dwconv.bias\",\n",
      "      \"stages.2.12.norm.weight\",\n",
      "      \"stages.2.12.norm.bias\",\n",
      "      \"stages.2.12.pwconv1.bias\",\n",
      "      \"stages.2.12.pwconv2.bias\",\n",
      "      \"stages.2.13.gamma\",\n",
      "      \"stages.2.13.dwconv.bias\",\n",
      "      \"stages.2.13.norm.weight\",\n",
      "      \"stages.2.13.norm.bias\",\n",
      "      \"stages.2.13.pwconv1.bias\",\n",
      "      \"stages.2.13.pwconv2.bias\",\n",
      "      \"stages.2.14.gamma\",\n",
      "      \"stages.2.14.dwconv.bias\",\n",
      "      \"stages.2.14.norm.weight\",\n",
      "      \"stages.2.14.norm.bias\",\n",
      "      \"stages.2.14.pwconv1.bias\",\n",
      "      \"stages.2.14.pwconv2.bias\",\n",
      "      \"stages.2.15.gamma\",\n",
      "      \"stages.2.15.dwconv.bias\",\n",
      "      \"stages.2.15.norm.weight\",\n",
      "      \"stages.2.15.norm.bias\",\n",
      "      \"stages.2.15.pwconv1.bias\",\n",
      "      \"stages.2.15.pwconv2.bias\",\n",
      "      \"stages.2.16.gamma\",\n",
      "      \"stages.2.16.dwconv.bias\",\n",
      "      \"stages.2.16.norm.weight\",\n",
      "      \"stages.2.16.norm.bias\",\n",
      "      \"stages.2.16.pwconv1.bias\",\n",
      "      \"stages.2.16.pwconv2.bias\",\n",
      "      \"stages.2.17.gamma\",\n",
      "      \"stages.2.17.dwconv.bias\",\n",
      "      \"stages.2.17.norm.weight\",\n",
      "      \"stages.2.17.norm.bias\",\n",
      "      \"stages.2.17.pwconv1.bias\",\n",
      "      \"stages.2.17.pwconv2.bias\",\n",
      "      \"stages.2.18.gamma\",\n",
      "      \"stages.2.18.dwconv.bias\",\n",
      "      \"stages.2.18.norm.weight\",\n",
      "      \"stages.2.18.norm.bias\",\n",
      "      \"stages.2.18.pwconv1.bias\",\n",
      "      \"stages.2.18.pwconv2.bias\",\n",
      "      \"stages.2.19.gamma\",\n",
      "      \"stages.2.19.dwconv.bias\",\n",
      "      \"stages.2.19.norm.weight\",\n",
      "      \"stages.2.19.norm.bias\",\n",
      "      \"stages.2.19.pwconv1.bias\",\n",
      "      \"stages.2.19.pwconv2.bias\",\n",
      "      \"stages.2.20.gamma\",\n",
      "      \"stages.2.20.dwconv.bias\",\n",
      "      \"stages.2.20.norm.weight\",\n",
      "      \"stages.2.20.norm.bias\",\n",
      "      \"stages.2.20.pwconv1.bias\",\n",
      "      \"stages.2.20.pwconv2.bias\",\n",
      "      \"stages.2.21.gamma\",\n",
      "      \"stages.2.21.dwconv.bias\",\n",
      "      \"stages.2.21.norm.weight\",\n",
      "      \"stages.2.21.norm.bias\",\n",
      "      \"stages.2.21.pwconv1.bias\",\n",
      "      \"stages.2.21.pwconv2.bias\",\n",
      "      \"stages.2.22.gamma\",\n",
      "      \"stages.2.22.dwconv.bias\",\n",
      "      \"stages.2.22.norm.weight\",\n",
      "      \"stages.2.22.norm.bias\",\n",
      "      \"stages.2.22.pwconv1.bias\",\n",
      "      \"stages.2.22.pwconv2.bias\",\n",
      "      \"stages.2.23.gamma\",\n",
      "      \"stages.2.23.dwconv.bias\",\n",
      "      \"stages.2.23.norm.weight\",\n",
      "      \"stages.2.23.norm.bias\",\n",
      "      \"stages.2.23.pwconv1.bias\",\n",
      "      \"stages.2.23.pwconv2.bias\",\n",
      "      \"stages.2.24.gamma\",\n",
      "      \"stages.2.24.dwconv.bias\",\n",
      "      \"stages.2.24.norm.weight\",\n",
      "      \"stages.2.24.norm.bias\",\n",
      "      \"stages.2.24.pwconv1.bias\",\n",
      "      \"stages.2.24.pwconv2.bias\",\n",
      "      \"stages.2.25.gamma\",\n",
      "      \"stages.2.25.dwconv.bias\",\n",
      "      \"stages.2.25.norm.weight\",\n",
      "      \"stages.2.25.norm.bias\",\n",
      "      \"stages.2.25.pwconv1.bias\",\n",
      "      \"stages.2.25.pwconv2.bias\",\n",
      "      \"stages.2.26.gamma\",\n",
      "      \"stages.2.26.dwconv.bias\",\n",
      "      \"stages.2.26.norm.weight\",\n",
      "      \"stages.2.26.norm.bias\",\n",
      "      \"stages.2.26.pwconv1.bias\",\n",
      "      \"stages.2.26.pwconv2.bias\",\n",
      "      \"stages.3.0.gamma\",\n",
      "      \"stages.3.0.dwconv.bias\",\n",
      "      \"stages.3.0.norm.weight\",\n",
      "      \"stages.3.0.norm.bias\",\n",
      "      \"stages.3.0.pwconv1.bias\",\n",
      "      \"stages.3.0.pwconv2.bias\",\n",
      "      \"stages.3.1.gamma\",\n",
      "      \"stages.3.1.dwconv.bias\",\n",
      "      \"stages.3.1.norm.weight\",\n",
      "      \"stages.3.1.norm.bias\",\n",
      "      \"stages.3.1.pwconv1.bias\",\n",
      "      \"stages.3.1.pwconv2.bias\",\n",
      "      \"stages.3.2.gamma\",\n",
      "      \"stages.3.2.dwconv.bias\",\n",
      "      \"stages.3.2.norm.weight\",\n",
      "      \"stages.3.2.norm.bias\",\n",
      "      \"stages.3.2.pwconv1.bias\",\n",
      "      \"stages.3.2.pwconv2.bias\",\n",
      "      \"norm.weight\",\n",
      "      \"norm.bias\",\n",
      "      \"head.bias\"\n",
      "    ],\n",
      "    \"lr_scale\": 1.0\n",
      "  }\n",
      "}\n",
      "Use Cosine LR scheduler\n",
      "Set warmup steps = 0\n",
      "Set warmup steps = 0\n",
      "Max WD = 0.0500000, Min WD = 0.0500000\n",
      "criterion = CrossEntropyLoss()\n",
      "Auto resume checkpoint: \n",
      "Start training for 15 epochs\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "Epoch: [0]  [ 0/96]  eta: 0:24:24  lr: 0.000400  min_lr: 0.000400  loss: 1.0088 (1.0088)  class_acc: 0.7500 (0.7500)  weight_decay: 0.0500 (0.0500)  time: 15.2582  data: 13.7499  max mem: 5259\n",
      "Epoch: [0]  [10/96]  eta: 0:03:54  lr: 0.000400  min_lr: 0.000400  loss: 0.9697 (0.9141)  class_acc: 0.7500 (0.6818)  weight_decay: 0.0500 (0.0500)  time: 2.7238  data: 2.0274  max mem: 5259\n",
      "Epoch: [0]  [20/96]  eta: 0:02:44  lr: 0.000400  min_lr: 0.000400  loss: 0.9422 (0.9606)  class_acc: 0.5000 (0.6429)  weight_decay: 0.0500 (0.0500)  time: 1.5084  data: 0.8830  max mem: 5259\n",
      "Epoch: [0]  [30/96]  eta: 0:02:02  lr: 0.000400  min_lr: 0.000400  loss: 1.0206 (0.9899)  class_acc: 0.5000 (0.5806)  weight_decay: 0.0500 (0.0500)  time: 1.3703  data: 0.7477  max mem: 5259\n",
      "Epoch: [0]  [40/96]  eta: 0:01:37  lr: 0.000399  min_lr: 0.000399  loss: 1.0206 (0.9890)  class_acc: 0.5000 (0.5793)  weight_decay: 0.0500 (0.0500)  time: 1.3069  data: 0.6806  max mem: 5259\n",
      "Epoch: [0]  [50/96]  eta: 0:01:20  lr: 0.000399  min_lr: 0.000399  loss: 0.9714 (0.9791)  class_acc: 0.5000 (0.5735)  weight_decay: 0.0500 (0.0500)  time: 1.5728  data: 0.9424  max mem: 5259\n",
      "Epoch: [0]  [60/96]  eta: 0:00:58  lr: 0.000398  min_lr: 0.000398  loss: 0.8707 (0.9600)  class_acc: 0.5000 (0.5615)  weight_decay: 0.0500 (0.0500)  time: 1.4157  data: 0.8044  max mem: 5259\n",
      "Epoch: [0]  [70/96]  eta: 0:00:41  lr: 0.000398  min_lr: 0.000398  loss: 0.7145 (0.9199)  class_acc: 0.7500 (0.5986)  weight_decay: 0.0500 (0.0500)  time: 1.2426  data: 0.6381  max mem: 5259\n",
      "Epoch: [0]  [80/96]  eta: 0:00:26  lr: 0.000397  min_lr: 0.000397  loss: 0.5638 (0.8887)  class_acc: 0.7500 (0.6204)  weight_decay: 0.0500 (0.0500)  time: 1.6566  data: 1.0658  max mem: 5259\n",
      "Epoch: [0]  [90/96]  eta: 0:00:09  lr: 0.000396  min_lr: 0.000396  loss: 0.6552 (0.8763)  class_acc: 0.7500 (0.6291)  weight_decay: 0.0500 (0.0500)  time: 1.4521  data: 0.9171  max mem: 5259\n",
      "Epoch: [0]  [95/96]  eta: 0:00:01  lr: 0.000396  min_lr: 0.000396  loss: 0.8205 (0.8644)  class_acc: 0.7500 (0.6354)  weight_decay: 0.0500 (0.0500)  time: 1.2035  data: 0.7221  max mem: 5259\n",
      "Epoch: [0] Total time: 0:02:25 (1.5146 s / it)\n",
      "Averaged stats: lr: 0.000396  min_lr: 0.000396  loss: 0.8205 (0.8644)  class_acc: 0.7500 (0.6354)  weight_decay: 0.0500 (0.0500)\n",
      "Test:  [ 0/33]  eta: 0:13:57  loss: 0.5587 (0.5587)  acc1: 66.6667 (66.6667)  acc5: 100.0000 (100.0000)  time: 25.3771  data: 25.0637  max mem: 5259\n",
      "Test:  [10/33]  eta: 0:01:43  loss: 0.4493 (0.4790)  acc1: 100.0000 (93.9394)  acc5: 100.0000 (100.0000)  time: 4.5014  data: 4.3500  max mem: 5259\n",
      "Test:  [20/33]  eta: 0:00:38  loss: 0.4268 (0.4168)  acc1: 100.0000 (91.2698)  acc5: 100.0000 (100.0000)  time: 1.8215  data: 1.6834  max mem: 5259\n",
      "Test:  [30/33]  eta: 0:00:07  loss: 0.4270 (0.6221)  acc1: 83.3333 (77.4194)  acc5: 100.0000 (100.0000)  time: 1.6041  data: 1.4602  max mem: 5259\n",
      "Test:  [32/33]  eta: 0:00:02  loss: 0.4278 (0.7109)  acc1: 83.3333 (74.6114)  acc5: 100.0000 (100.0000)  time: 1.6021  data: 1.4602  max mem: 5259\n",
      "Test: Total time: 0:01:22 (2.4885 s / it)\n",
      "* Acc@1 74.611 Acc@5 100.000 loss 0.711\n",
      "Accuracy of the model on the 193 test images: 74.6%\n",
      "Max accuracy: 74.61%\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:405: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "Epoch: [1]  [ 0/96]  eta: 0:27:56  lr: 0.000396  min_lr: 0.000396  loss: 0.4581 (0.4581)  class_acc: 0.7500 (0.7500)  weight_decay: 0.0500 (0.0500)  time: 17.4607  data: 16.3679  max mem: 5259\n",
      "Epoch: [1]  [10/96]  eta: 0:04:28  lr: 0.000395  min_lr: 0.000395  loss: 0.4581 (0.4737)  class_acc: 0.7500 (0.7955)  weight_decay: 0.0500 (0.0500)  time: 3.1201  data: 2.3080  max mem: 5259\n",
      "Epoch: [1]  [20/96]  eta: 0:03:02  lr: 0.000394  min_lr: 0.000394  loss: 0.6502 (0.6566)  class_acc: 0.7500 (0.7500)  weight_decay: 0.0500 (0.0500)  time: 1.6415  data: 0.9418  max mem: 5259\n",
      "Epoch: [1]  [30/96]  eta: 0:02:13  lr: 0.000393  min_lr: 0.000393  loss: 0.7093 (0.6740)  class_acc: 0.7500 (0.7339)  weight_decay: 0.0500 (0.0500)  time: 1.4173  data: 0.8065  max mem: 5259\n",
      "Epoch: [1]  [40/96]  eta: 0:01:45  lr: 0.000391  min_lr: 0.000391  loss: 0.6639 (0.6882)  class_acc: 0.7500 (0.7195)  weight_decay: 0.0500 (0.0500)  time: 1.3626  data: 0.7474  max mem: 5259\n",
      "Epoch: [1]  [50/96]  eta: 0:01:25  lr: 0.000390  min_lr: 0.000390  loss: 0.6350 (0.6921)  class_acc: 0.7500 (0.7108)  weight_decay: 0.0500 (0.0500)  time: 1.6104  data: 0.9738  max mem: 5259\n",
      "Epoch: [1]  [60/96]  eta: 0:01:02  lr: 0.000389  min_lr: 0.000389  loss: 0.5376 (0.6664)  class_acc: 0.7500 (0.7295)  weight_decay: 0.0500 (0.0500)  time: 1.3985  data: 0.7727  max mem: 5259\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 485, in <module>\n",
      "    main(args)\n",
      "  File \"main.py\", line 416, in main\n",
      "    use_amp=args.use_amp\n",
      "  File \"/content/drive/MyDrive/AI/neurowood/ConvNeXt/engine.py\", line 56, in train_one_epoch\n",
      "    output = model(samples)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/content/drive/MyDrive/AI/neurowood/ConvNeXt/models/convnext.py\", line 115, in forward\n",
      "    x = self.forward_features(x)\n",
      "  File \"/content/drive/MyDrive/AI/neurowood/ConvNeXt/models/convnext.py\", line 110, in forward_features\n",
      "    x = self.downsample_layers[i](x)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/content/drive/MyDrive/AI/neurowood/ConvNeXt/models/convnext.py\", line 139, in forward\n",
      "    u = x.mean(1, keepdim=True)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%cd ConvNeXt\n",
    "!python3 main.py --epochs 15 \\\n",
    "                --batch_size=4 \\\n",
    "                --model convnext_base \\\n",
    "                --input_size=384 \\\n",
    "                --warmup_epochs=15 \\\n",
    "                --smoothing=0 \\\n",
    "                --save_ckpt_freq=10 \\\n",
    "                --save_ckpt_num=1 \\\n",
    "                --data_set image_folder \\\n",
    "                --data_path ../data/ \\\n",
    "                --nb_classes 3 \\\n",
    "                --num_workers 8 \\\n",
    "                --warmup_epochs 0 \\\n",
    "                --save_ckpt true \\\n",
    "                --output_dir checkpoints \\\n",
    "                --finetune weights/convnext_base_1k_384.pth \\\n",
    "                --cutmix 0 \\\n",
    "                --mixup 0 --lr 4e-4 \\\n",
    "                --enable_wandb false --wandb_ckpt false"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ViT"
   ],
   "metadata": {
    "id": "jvb82BI63X8I"
   },
   "id": "jvb82BI63X8I"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets transformers -qq"
   ],
   "metadata": {
    "id": "XLBzLjiT-XWR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650108279209,
     "user_tz": -120,
     "elapsed": 4339,
     "user": {
      "displayName": "Nikita Dilman",
      "userId": "06419702465665096398"
     }
    }
   },
   "id": "XLBzLjiT-XWR",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%cd ViT\n",
    "!python3 main.py --batch_size=16 \\\n",
    "                  --epochs 4 \\\n",
    "                  --seed 0 \\\n",
    "                  --n_splits 3\\\n",
    "                  --n_fold 3 \\\n",
    "                  --model_name_or_path google/vit-base-patch32-384 \\\n",
    "                  --data_path ../data/ \\\n",
    "                  --output_dir ./vit-base-patch32-384_fold3"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feElV0yw3Zjr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650118259327,
     "user_tz": -120,
     "elapsed": 891904,
     "user": {
      "displayName": "Nikita Dilman",
      "userId": "06419702465665096398"
     }
    },
    "outputId": "5eae794e-d00d-4afe-8a2b-aba11633a238"
   },
   "id": "feElV0yw3Zjr",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: 'ViT'\n",
      "/content/drive/MyDrive/AI/neurowood/ViT\n",
      "Namespace(batch_size=16, data_path='../data/', epochs=4, lr=0.0002, model_name_or_path='google/vit-base-patch32-384', n_fold=3, n_splits=3, output_dir='./vit-base-patch32-384_fold3', seed=0)\n",
      "100% 386/386 [00:00<00:00, 722123.70it/s]\n",
      "100% 192/192 [00:00<00:00, 698444.38it/s]\n",
      "Reusing dataset superb (/root/.cache/huggingface/datasets/superb/ks/1.9.0/b8183f71eabe8c559d7f3f528ab37a6a21ad1ee088fd3423574cecad8b3ec67e)\n",
      "100% 3/3 [00:00<00:00, 80.40it/s]\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch32-384 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using amp half precision backend\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 386\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n",
      "{'loss': 0.8747, 'learning_rate': 0.000182, 'epoch': 0.4}\n",
      "{'loss': 0.5667, 'learning_rate': 0.000162, 'epoch': 0.8}\n",
      "{'loss': 0.2077, 'learning_rate': 0.000142, 'epoch': 1.2}\n",
      "{'loss': 0.0647, 'learning_rate': 0.000122, 'epoch': 1.6}\n",
      "{'loss': 0.0829, 'learning_rate': 0.00010200000000000001, 'epoch': 2.0}\n",
      "{'loss': 0.1323, 'learning_rate': 8.2e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0053, 'learning_rate': 6.2e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0009, 'learning_rate': 4.2e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0008, 'learning_rate': 2.2000000000000003e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0006, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.0}\n",
      "100% 100/100 [11:20<00:00,  4.88s/it]***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 8\n",
      "\n",
      "  0% 0/24 [00:00<?, ?it/s]\u001B[A\n",
      "  8% 2/24 [00:04<00:48,  2.22s/it]\u001B[A\n",
      " 12% 3/24 [00:08<01:06,  3.15s/it]\u001B[A\n",
      " 17% 4/24 [00:13<01:12,  3.62s/it]\u001B[A\n",
      " 21% 5/24 [00:17<01:14,  3.90s/it]\u001B[A\n",
      " 25% 6/24 [00:22<01:13,  4.09s/it]\u001B[A\n",
      " 29% 7/24 [00:26<01:11,  4.22s/it]\u001B[A\n",
      " 33% 8/24 [00:31<01:08,  4.27s/it]\u001B[A\n",
      " 38% 9/24 [00:35<01:04,  4.30s/it]\u001B[A\n",
      " 42% 10/24 [00:39<01:00,  4.34s/it]\u001B[A\n",
      " 46% 11/24 [00:44<00:56,  4.36s/it]\u001B[A\n",
      " 50% 12/24 [00:48<00:53,  4.42s/it]\u001B[A\n",
      " 54% 13/24 [00:53<00:48,  4.42s/it]\u001B[A\n",
      " 58% 14/24 [00:55<00:38,  3.90s/it]\u001B[A\n",
      " 62% 15/24 [00:57<00:29,  3.23s/it]\u001B[A\n",
      " 67% 16/24 [00:59<00:22,  2.81s/it]\u001B[A\n",
      " 71% 17/24 [01:01<00:17,  2.51s/it]\u001B[A\n",
      " 75% 18/24 [01:03<00:13,  2.29s/it]\u001B[A\n",
      " 79% 19/24 [01:04<00:10,  2.02s/it]\u001B[A\n",
      " 83% 20/24 [01:06<00:08,  2.02s/it]\u001B[A\n",
      " 88% 21/24 [01:07<00:05,  1.87s/it]\u001B[A\n",
      " 92% 22/24 [01:10<00:04,  2.17s/it]\u001B[A\n",
      " 96% 23/24 [01:15<00:02,  2.80s/it]\u001B[A\n",
      "                                     \n",
      "\u001B[A{'eval_loss': 0.10799574851989746, 'eval_accuracy': 0.9791666666666666, 'eval_runtime': 84.504, 'eval_samples_per_second': 2.272, 'eval_steps_per_second': 0.284, 'epoch': 4.0}\n",
      "100% 100/100 [12:45<00:00,  4.88s/it]\n",
      "100% 24/24 [01:20<00:00,  3.28s/it]\u001B[A\n",
      "                                   \u001B[ASaving model checkpoint to ./vit-base-patch32-384_fold3/checkpoint-100\n",
      "Configuration saved in ./vit-base-patch32-384_fold3/checkpoint-100/config.json\n",
      "Model weights saved in ./vit-base-patch32-384_fold3/checkpoint-100/pytorch_model.bin\n",
      "Feature extractor saved in ./vit-base-patch32-384_fold3/checkpoint-100/preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./vit-base-patch32-384_fold3/checkpoint-100 (score: 0.10799574851989746).\n",
      "{'train_runtime': 770.7616, 'train_samples_per_second': 2.003, 'train_steps_per_second': 0.13, 'train_loss': 0.19366026118397714, 'epoch': 4.0}\n",
      "100% 100/100 [12:50<00:00,  7.71s/it]\n",
      "Saving model checkpoint to ./vit-base-patch32-384_fold3\n",
      "Configuration saved in ./vit-base-patch32-384_fold3/config.json\n",
      "Model weights saved in ./vit-base-patch32-384_fold3/pytorch_model.bin\n",
      "Feature extractor saved in ./vit-base-patch32-384_fold3/preprocessor_config.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        4.0\n",
      "  train_loss               =     0.1937\n",
      "  train_runtime            = 0:12:50.76\n",
      "  train_samples_per_second =      2.003\n",
      "  train_steps_per_second   =       0.13\n",
      "Training time 0:12:52\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 192\n",
      "  Batch size = 8\n",
      "100% 24/24 [01:21<00:00,  3.39s/it]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        4.0\n",
      "  eval_accuracy           =     0.9792\n",
      "  eval_loss               =      0.108\n",
      "  eval_runtime            = 0:01:27.01\n",
      "  eval_samples_per_second =      2.207\n",
      "  eval_steps_per_second   =      0.276\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd ViT\n",
    "!python3 inference.py --data_path ../data/test \\\n",
    "                      --tta 1 \\\n",
    "                      --checkpoint_path vit-base-beans-demo-v5 \\\n",
    "                      --submit_file vit.csv"
   ],
   "metadata": {
    "id": "Fu98oI6n-MqW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650128971841,
     "user_tz": -120,
     "elapsed": 2940791,
     "user": {
      "displayName": "Nikita Dilman",
      "userId": "06419702465665096398"
     }
    },
    "outputId": "599d77ab-23b9-41d0-a61a-9a07c3f61238"
   },
   "id": "Fu98oI6n-MqW",
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: 'ViT'\n",
      "/content/drive/MyDrive/AI/neurowood/ViT\n",
      "100% 249/249 [48:43<00:00, 11.74s/it]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "uy8HHy6rZbOj"
   },
   "id": "uy8HHy6rZbOj",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "3708861a-82ad-402d-ae89-31e3fc3145d4",
  "notebookPath": "ConvNeXt/Training.ipynb",
  "colab": {
   "name": "Training.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}